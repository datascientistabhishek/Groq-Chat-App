# ðŸŒŸ Groq Chat App ðŸŒŸ

## Table of Contents
- [Overview](#overview)
- [Installation](#installation)
- [Usage](#usage)
- [Customization](#customization)
- [Contributing](#contributing)
- [License](#license)

## Overview
Welcome to the Groq Chat App! This project is a web-based chat application that utilizes the power of Large Language Models (LLMs) to provide intelligent and engaging conversations with users. Built using Streamlit and the Groq API, this app offers a seamless and intuitive interface for users to interact with cutting-edge language models.

## Installation
To install the Groq Chat App, simply clone the repository and install the required dependencies:
-`git clone https://github.com/datascientistabhishek/groq-chat-app.git
-cd groq-chat-app
-pip install -r requirements.txt`

## Usage
Once installed, you can launch the app by running the following command:
-`streamlit run app.py`
This will open a new browser window or tab, displaying the Groq Chat App interface. Simply type your questions or messages in the text area and hit enter to receive responses from the LLM.

## Customization
The Groq Chat App offers a range of customization options to tailor the conversation experience:
- **LLM Selection:** Choose from a variety of powerful LLMs, such as Mixtral-8x7b-32768 or Llama-3.1-70b-versatile, to power your conversations.
- **Conversational Memory:** Adjust the conversational memory length to control how much context the LLM retains from previous messages.

## Contributing
We welcome contributions to the Groq Chat App! If you have suggestions, improvements, or bug fixes, feel free to create a pull request or open an issue. Please refer to our contributing guidelines for more details.

## License
This project is licensed under the MIT License.
